{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333368e3-bb42-466c-8823-c45ed71f970f",
   "metadata": {},
   "source": [
    "# Prospecção de Dados (Data Mining) DI/FCUL - HA1\n",
    "\n",
    "## First Home Assignement (MC/DI/FCUL - 2024)\n",
    "\n",
    "### Fill in the section below\n",
    "\n",
    "### GROUP: `02`\n",
    "\n",
    "* João Martins, 62532 - Hours worked on the project: 16\n",
    "* Rúben Torres, 62531 - Hours worked on the project: 16\n",
    "* Nuno Pereira, 56933 - Hours worked on the project\n",
    "\n",
    "The purpose of this Home Assignment is:\n",
    "* Read a Data file with a Set of Texts\n",
    "* Compute similarities between texts\n",
    "* Perform simple classification of texts using a Naive Bayes classifier\n",
    "\n",
    "**NOTE 1: Students are not allowed to add more cells to the notebook**\n",
    "\n",
    "**NOTE 2: The notebook must be submited fully executed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a40f24-0da5-4b96-90f3-84259cbd1bc5",
   "metadata": {},
   "source": [
    "## 1. Read the Dataset\n",
    "\n",
    "The dataset is the file `Sentences_75Agree.txt` from the [Financial Sentiment Analysis database on Hugging Face](https://huggingface.co/datasets/financial_phrasebank)\n",
    "\n",
    "* Read the dataset and separate them by unique documents (one document per line)\n",
    "* The last word of each document is the class and it **must be removed from the document** but kept separate for use in the classification tasks below\n",
    "    * classes can be `.@positive`, `.@negative` or `.@neutral`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa918e91-c325-4c1d-8e8d-93d411035a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from math import log2\n",
    "from random import sample, shuffle\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "from statistics import mean, stdev\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "FILE_NAME: str = \"Sentences_75Agree.txt\"\n",
    "CLASS_DELIMITER: str = \"@\"\n",
    "\n",
    "\n",
    "def classify_document(document: str) -> dict[str, str]:\n",
    "    s: str = document.strip().split(CLASS_DELIMITER)\n",
    "    return {\"document\": s[0], \"class\": s[-1]}\n",
    "\n",
    "\n",
    "documents: list[str] = open(FILE_NAME, encoding=\"ISO-8859-15\").readlines()\n",
    "documents_classified: list[dict[str, str]] = [\n",
    "    classify_document(document) for document in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853614f3-1e1b-4481-9784-e29dd0b453cb",
   "metadata": {},
   "source": [
    "## 2. Compute similarities between texts\n",
    "\n",
    "* Compute the TF.IDF of all words in texts\n",
    "* compute the average similarity beween texts\n",
    "* Plot the document similarity distribution (suggestion use [boxplots](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html) or [histograms](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html) or [histograms with density](https://matplotlib.org/stable/gallery/statistics/histogram_features.html))\n",
    "* Comment your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead806d9-8073-4fc0-9668-68ad0b89077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CORPUS Start ========== #\n",
    "\n",
    "\n",
    "def basic_word_tokenizer(text: str) -> list[str]:\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def remove_accents(text: str) -> str:\n",
    "    nfkd_form: str = unicodedata.normalize(\"NFKD\", text)\n",
    "    return \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "\n",
    "def remove_stuff(text: str) -> str:\n",
    "    for c in '\\\\\\t0123456789Ææœ—‘’\\ufeff{|}“”.,()$£%&[]?@#!=;*+–\"ǁ':\n",
    "        text = text.replace(c, \"\")\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_words_from_text(text: str) -> list[str]:\n",
    "    text = text.strip().lower()\n",
    "    text = remove_accents(text)\n",
    "    text = remove_stuff(text)\n",
    "    text = text.lower()\n",
    "    return basic_word_tokenizer(text)\n",
    "\n",
    "\n",
    "def get_words_from_corpus(corpus: list[str]) -> list[list[str]]:\n",
    "    return [get_words_from_text(text) for text in corpus]\n",
    "\n",
    "\n",
    "# ========== CORPUS End ========== #\n",
    "\n",
    "# ========== TF Start ========== #\n",
    "\n",
    "\n",
    "def word_counter(words: list[str]) -> dict[str, int]:\n",
    "    unique_words: set[str] = set(words)\n",
    "    counter: dict[str, int] = dict(zip(unique_words, [0] * len(unique_words)))\n",
    "    for word in words:\n",
    "        counter[word] += 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "def TF(word_counts: dict[str, int]) -> dict[str, int]:\n",
    "    counts: list[int] = list(word_counts.values())\n",
    "    if len(counts) == 0:\n",
    "        return {}\n",
    "    counts_max: int = max(counts)\n",
    "    return dict(zip(word_counts.keys(), [count / counts_max for count in counts]))\n",
    "\n",
    "\n",
    "def TF_all(words_texts: list[list[str]]) -> list[dict[str, int]]:\n",
    "    return [TF(word_counter(words)) for words in words_texts]\n",
    "\n",
    "\n",
    "# ========== TF End ========== #\n",
    "\n",
    "# ========== IDF Start ========== #\n",
    "\n",
    "\n",
    "def IDF_all(words_texts_sets: list[set[str]]) -> dict[str, float]:\n",
    "    all_words: set[str] = set.union(*words_texts_sets)\n",
    "    counter: dict[str, int] = dict(zip(all_words, [0] * len(all_words)))\n",
    "    total_number_of_documents: int = len(words_texts_sets)\n",
    "    for words in words_texts_sets:\n",
    "        for word in words:\n",
    "            counter[word] += 1\n",
    "    return {word: log2(total_number_of_documents / counter[word]) for word in counter}\n",
    "\n",
    "\n",
    "# ========== IDF End ========== #\n",
    "\n",
    "# ========== TF-IDF Start ========== #\n",
    "\n",
    "\n",
    "def TF_IDF_cosine_similarity(\n",
    "    idx1: int,\n",
    "    idx2: int,\n",
    "    words_texts_sets: list[set[str]],\n",
    "    all_tfs: list[dict[str, int]],\n",
    "    all_idfs: dict[str, float],\n",
    ") -> float:\n",
    "    text1: set[str] = words_texts_sets[idx1]\n",
    "    text2: set[str] = words_texts_sets[idx2]\n",
    "    common_words: set[str] = text1 & text2\n",
    "    if len(common_words) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    tfs1: dict[str, int] = all_tfs[idx1]\n",
    "    tfs2: dict[str, int] = all_tfs[idx2]\n",
    "    common_tfidfs: list[float] = [\n",
    "        tfs1[word] * tfs2[word] * all_idfs[word] * all_idfs[word]\n",
    "        for word in common_words\n",
    "    ]\n",
    "\n",
    "    tfidfs2_1 = np.array([tfs1[word] * all_idfs[word] for word in text1]) ** 2\n",
    "    tfidfs2_2 = np.array([tfs2[word] * all_idfs[word] for word in text2]) ** 2\n",
    "\n",
    "    return sum(common_tfidfs) / (np.sqrt(tfidfs2_1.sum()) * np.sqrt(tfidfs2_2.sum()))\n",
    "\n",
    "\n",
    "def text_similarities(\n",
    "    words_texts_sets: list[set[str]],\n",
    "    all_tfs: list[dict[str, int]],\n",
    "    all_idfs: dict[str, float],\n",
    ") -> list[tuple[float, tuple[int, int]]]:\n",
    "    total_number_of_documents: int = len(words_texts_sets)\n",
    "    return [\n",
    "        (TF_IDF_cosine_similarity(i, j, words_texts_sets, all_tfs, all_idfs), (i, j))\n",
    "        for i in range(total_number_of_documents - 1)\n",
    "        for j in range(i + 1, total_number_of_documents)\n",
    "    ]\n",
    "\n",
    "\n",
    "# ========== TF-IDF End ========== #\n",
    "\n",
    "# ========== Distribution Start ========== #\n",
    "\n",
    "\n",
    "def plot_distribution(mean: float, stdev: float) -> None:\n",
    "    x = np.linspace(0.0, 1.0, 100)\n",
    "    y = norm.pdf(x, mean, stdev)\n",
    "\n",
    "    plt.plot(x, y, label=\"Distribution\", color=\"blue\")\n",
    "    plt.axvline(x=mean, linestyle=\"--\", color=\"red\", label=\"Mean\")\n",
    "    plt.title(f\"Distribution (mean={mean} and stdev={stdev})\")\n",
    "    plt.xlabel(\"Similarities (between texts)\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ========== Distribution End ========== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80328c-ffba-4bb6-8ce3-03726ee82348",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus: list[str] = [\n",
    "    document_classified[\"document\"] for document_classified in documents_classified\n",
    "]\n",
    "\n",
    "words_texts: list[list[str]] = get_words_from_corpus(corpus)\n",
    "all_tfs: list[dict[str, int]] = TF_all(words_texts)\n",
    "\n",
    "words_texts_sets: list[set[str]] = [set(words) for words in words_texts]\n",
    "all_idfs: dict[str, float] = IDF_all(words_texts_sets)\n",
    "\n",
    "similarities: list[tuple[float, tuple[int, int]]] = text_similarities(\n",
    "    words_texts_sets, all_tfs, all_idfs\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "values: list[float] = [min(1.0, similarity) for similarity, _ in similarities]\n",
    "values_mean: float = mean(values)\n",
    "values_stdev: float = stdev(values)\n",
    "plot_distribution(values_mean, values_stdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a87b8-4102-43ff-ac7c-e748df7bcd1f",
   "metadata": {},
   "source": [
    "### Your short analysis here\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8043c37-3a4d-4c4d-ab3e-2fae63af06fa",
   "metadata": {},
   "source": [
    "## 3. Make a Naive Bayes Classifier \n",
    "\n",
    "* Split dataset randomly into training and testing (20% for testing)\n",
    "* Train a Naive Bayes Model and do some sensitivity analysis on the hyperparameters \n",
    "* Evaluate your results with the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedab1a-54d8-49a3-8c08-4815bfc7d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add supporting functions here\n",
    "\n",
    "def make_train_test(X: list[str], y: list[int], r: float = 0.2) -> Tuple[list[str], list[int], list[str], list[int]]:\n",
    "    N: int = len(X)\n",
    "    test_idx: set = set(sample(range(N), int(N*r)))\n",
    "    train_idx: list = list(set(range(N)) - test_idx)\n",
    "    test_idx: list =list(test_idx)\n",
    "    shuffle(train_idx)\n",
    "    shuffle(test_idx)\n",
    "    train_set_X: list[str] = [X[i] for i in train_idx]\n",
    "    train_set_y: list[str] = [y[i] for i in train_idx]\n",
    "    test_set_X: list[str] = [X[i] for i in test_idx]\n",
    "    test_set_y: list[str] = [y[i] for i in test_idx]\n",
    "    return train_set_X, train_set_y, test_set_X, test_set_y\n",
    "\n",
    "\n",
    "def calc_prior_counts(labels: list[int]) -> list[float]:\n",
    "    yv, yc = np.unique(labels, return_counts=True)\n",
    "    priors: np.ndarray =np.ones(len(yv))\n",
    "    priors[yv]=yc\n",
    "    return priors\n",
    "\n",
    "def calc_all_words(words_text_sets: list[set]) -> list[str]:\n",
    "    all_words: set = set()\n",
    "    for words in words_text_sets: \n",
    "        all_words |= words\n",
    "    return all_words\n",
    "\n",
    "\n",
    "def init_likelihood_counts(docs_words: list[list[str]], n_labels: int) -> dict:\n",
    "    all_words: list[str] =calc_all_words(docs_words)\n",
    "    L_hoods: dict = {}\n",
    "    for w in all_words:\n",
    "        L_hoods[w]=np.zeros(n_labels)\n",
    "    return L_hoods\n",
    "\n",
    "def update_likelihood_counts(L_hoods: dict, words: list[str], label: int) -> None:\n",
    "    for word in words: \n",
    "        L_hoods[word][label]+=1\n",
    "\n",
    "def calc_likelihood_counts(docs_words: list[list[str]], labels: list[int]) -> dict:\n",
    "    n_labels: int = len(set(labels))\n",
    "    L_hoods: dict = init_likelihood_counts(docs_words, n_labels)\n",
    "    for i, words in enumerate(docs_words): \n",
    "        update_likelihood_counts(L_hoods, words, labels[i])\n",
    "    return L_hoods\n",
    "\n",
    "def classify_new_document(words: list[str], priors: np.ndarray, L_hoods: dict, alpha: float = 0) -> list[float]:\n",
    "    res: np.ndarray = priors / priors.sum()\n",
    "    alpha_vec: np.ndarray = np.ones(len(res))*alpha\n",
    "    for word in words:\n",
    "        if word in L_hoods: \n",
    "            res*=(L_hoods[word]/L_hoods[word].sum() + alpha_vec)\n",
    "    return res/res.sum()\n",
    "\n",
    "def classify_documents(docs: list[list[str]], priors: np.ndarray, L_hoods: dict, alpha: float = 0) -> list[int]:\n",
    "    return [classify_new_document(words, priors, L_hoods, alpha).argmax(axis=0) for words in docs]\n",
    "\n",
    "def calc_posterior(data: list[str], priors: np.ndarray, L_hoods: dict) -> dict:\n",
    "    probs: np.ndarray = np.zeros(len(priors))\n",
    "    for j, yp in enumerate(priors.keys()):\n",
    "        probs[j] = priors[yp]\n",
    "        for i, d in enumerate(data): \n",
    "            probs[j] *= L_hoods[(i, d, yp)]\n",
    "    #scaling to 1.0\n",
    "    probs=probs/np.sum(probs)\n",
    "    return {yp: probs[j] for j, yp in enumerate(priors.keys())}\n",
    "\n",
    "def model_evaluation(y_test: list[int], preds: list[int]) -> None:\n",
    "    print(\"The Accuracy score is: %7.4f\" % accuracy_score(y_test, preds))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(y_test, preds, average='weighted'))\n",
    "    print(\"The MCC score is: %7.4f\" % matthews_corrcoef(y_test, preds))\n",
    "    print(\"The precision score is: %7.4f\" %  precision_score(y_test, preds, average='weighted'))\n",
    "    print(\"The recall score is: %7.4f\" %  recall_score(y_test, preds, average='weighted'))\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "\n",
    "def plot_diferent_aplha_values(x_test: list[str], y_test: list[int], PC: np.ndarray, LHC: dict, preds: list[int], alphas: list[float]) -> None:\n",
    "    f1_scores: list[float] = []\n",
    "    matthews_corrcoefs: list[float] = []\n",
    "    precision_scores: list[float] = []\n",
    "    recall_scores: list[float] = []\n",
    "\n",
    "    for i in alphas:\n",
    "        preds=classify_documents(x_test, PC, LHC, alpha=i)\n",
    "        f1_scores.append(f1_score(y_test, preds, average='weighted', zero_division=1))\n",
    "        matthews_corrcoefs.append(matthews_corrcoef(y_test, preds))\n",
    "        precision_scores.append(precision_score(y_test, preds, average='weighted', zero_division=1))\n",
    "        recall_scores.append(recall_score(y_test, preds, average='weighted', zero_division=1))\n",
    "\n",
    "    plt.plot(alphas, f1_scores,'b-', marker = \"o\", label='F1')\n",
    "    plt.plot(alphas, matthews_corrcoefs,'g-', marker = \"o\", label='mathews_corr')\n",
    "    plt.plot(alphas, precision_scores,'r-', marker = \"o\", label='precision')\n",
    "    plt.plot(alphas, recall_scores,'k-', marker = \"o\", label='recall')\n",
    "    plt.xlabel(\"Alpha values\")\n",
    "    plt.ylabel(\"Scores\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_class_balance(data: list[int]) -> None:\n",
    "    classes = ['negative', 'neutral', 'positive']\n",
    "    \n",
    "    yv, yc=np.unique(data, return_counts=True)\n",
    "    plt.bar(classes, yc, color ='blue', width = 0.6)\n",
    " \n",
    "    plt.xlabel(\"Nº classes\")\n",
    "    plt.ylabel(\"No. of instances\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72095268-f6c8-4156-98ce-662952ba22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_encoding: dict = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "y_corpus: list[str] = [class_encoding[documents_classified[\"class\"]] for documents_classified in documents_classified]\n",
    "x_corpus = words_texts_sets\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_train_test(x_corpus, y_corpus, r=0.2)\n",
    "\n",
    "\n",
    "PC: list[float] = calc_prior_counts(y_train)\n",
    "LHC: list[float] = calc_likelihood_counts(x_train, y_train)\n",
    "\n",
    "preds: list[int]=classify_documents(x_test, PC, LHC, alpha=0.0001)\n",
    "\n",
    "# for i, words in enumerate(x_test[:10]):\n",
    "#     print(i, \"--\", preds[i], \"<--\", words)\n",
    "\n",
    "model_evaluation(y_test, preds)\n",
    "\n",
    "\n",
    "alphas: list[int] = [0.001, 0.005, 0.015, 0.025, 0.05, 0.1, 0.15]\n",
    "plot_diferent_aplha_values(x_test, y_test, PC, LHC, preds, alphas)\n",
    "plot_class_balance(y_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f4a00-01db-4c2c-a7b7-0a0f7ab0d333",
   "metadata": {},
   "source": [
    "## 4. Discuss your findings [to fill on your own]\n",
    "\n",
    "* Comment your results above\n",
    "* Discuss how could they be used in a Big Data environment\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
